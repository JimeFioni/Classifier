{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow transformers datasets tensorboard scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- Preprocesamiento de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import TFBertModel, BertTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Cargar los datos\n",
    "data = pd.read_csv('tu_archivo.csv')\n",
    "\n",
    "# Inicializar el tokenizador de BERT\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Preprocesar los textos\n",
    "def tokenize_texts(texts, tokenizer, max_len=128):\n",
    "    return tokenizer(\n",
    "        texts.tolist(),\n",
    "        max_length=max_len,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='tf'\n",
    "    )\n",
    "\n",
    "tokenized_texts = tokenize_texts(data['comentario'], tokenizer)\n",
    "\n",
    "# Convertir etiquetas en clases (para SEGMENTO, PAIS, PERIODO, SENTIMIENTO)\n",
    "label_encoder_segmento = LabelEncoder()\n",
    "label_encoder_pais = LabelEncoder()\n",
    "label_encoder_periodo = LabelEncoder()\n",
    "label_encoder_sentimiento = LabelEncoder()\n",
    "\n",
    "data['segmento'] = label_encoder_segmento.fit_transform(data['segmento'])\n",
    "data['pais'] = label_encoder_pais.fit_transform(data['pais'])\n",
    "data['periodo'] = label_encoder_periodo.fit_transform(data['periodo'])\n",
    "data['sentimiento'] = label_encoder_sentimiento.fit_transform(data['sentimiento'])\n",
    "\n",
    "# Dividir datos en entrenamiento y validación\n",
    "X_train_texts, X_val_texts, y_train, y_val = train_test_split(tokenized_texts, data[['segmento', 'pais', 'periodo', 'sentimiento']], test_size=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3- Modelo Multitarea usando BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo Multitarea usando BERT\n",
    "def create_multitask_model():\n",
    "    # Capa BERT para extraer embeddings\n",
    "    bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "    \n",
    "    # Entrada de BERT\n",
    "    input_ids = tf.keras.layers.Input(shape=(128,), dtype=tf.int32, name=\"input_ids\")\n",
    "    attention_mask = tf.keras.layers.Input(shape=(128,), dtype=tf.int32, name=\"attention_mask\")\n",
    "    \n",
    "    bert_output = bert_model(input_ids, attention_mask=attention_mask)[1]  # Tomamos el embedding del [CLS]\n",
    "    \n",
    "    # Capas densas para cada tarea\n",
    "    sentiment_output = tf.keras.layers.Dense(3, activation='softmax', name='sentiment_output')(bert_output)  # Clasificación de Sentimientos (Positivo, Negativo, Neutro)\n",
    "    segmento_output = tf.keras.layers.Dense(len(label_encoder_segmento.classes_), activation='softmax', name='segmento_output')(bert_output)\n",
    "    pais_output = tf.keras.layers.Dense(len(label_encoder_pais.classes_), activation='softmax', name='pais_output')(bert_output)\n",
    "    periodo_output = tf.keras.layers.Dense(len(label_encoder_periodo.classes_), activation='softmax', name='periodo_output')(bert_output)\n",
    "    \n",
    "    # Definir el modelo\n",
    "    model = tf.keras.Model(inputs=[input_ids, attention_mask], outputs=[sentiment_output, segmento_output, pais_output, periodo_output])\n",
    "    \n",
    "    # Compilar el modelo con diferentes pérdidas para cada salida\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),\n",
    "        loss={\n",
    "            'sentiment_output': 'sparse_categorical_crossentropy',\n",
    "            'segmento_output': 'sparse_categorical_crossentropy',\n",
    "            'pais_output': 'sparse_categorical_crossentropy',\n",
    "            'periodo_output': 'sparse_categorical_crossentropy'\n",
    "        },\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Crear el modelo\n",
    "model = create_multitask_model()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4- Configuración de Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo\n",
    "history = model.fit(\n",
    "    [X_train_texts['input_ids'], X_train_texts['attention_mask']],\n",
    "    [y_train['sentimiento'], y_train['segmento'], y_train['pais'], y_train['periodo']],\n",
    "    validation_data=(\n",
    "        [X_val_texts['input_ids'], X_val_texts['attention_mask']],\n",
    "        [y_val['sentimiento'], y_val['segmento'], y_val['pais'], y_val['periodo']]\n",
    "    ),\n",
    "    epochs=3,\n",
    "    batch_size=16,\n",
    "    callbacks=[tensorboard_callback]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5- Entrenamiento del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo\n",
    "history = model.fit(\n",
    "    [X_train_texts['input_ids'], X_train_texts['attention_mask']],\n",
    "    [y_train['sentimiento'], y_train['segmento'], y_train['pais'], y_train['periodo']],\n",
    "    validation_data=(\n",
    "        [X_val_texts['input_ids'], X_val_texts['attention_mask']],\n",
    "        [y_val['sentimiento'], y_val['segmento'], y_val['pais'], y_val['periodo']]\n",
    "    ),\n",
    "    epochs=3,\n",
    "    batch_size=16,\n",
    "    callbacks=[tensorboard_callback]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard --logdir=logs/fit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6- Evaluación y guardado del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el modelo\n",
    "model.evaluate(\n",
    "    [X_val_texts['input_ids'], X_val_texts['attention_mask']],\n",
    "    [y_val['sentimiento'], y_val['segmento'], y_val['pais'], y_val['periodo']]\n",
    ")\n",
    "\n",
    "# Guardar el modelo entrenado\n",
    "model.save('modelo_multitarea_bert.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7- Carga y uso del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el modelo\n",
    "new_model = tf.keras.models.load_model('modelo_multitarea_bert.h5')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
